import Foundation
import Logging
import ContainerBridge
import Containerization
import NIOHTTP1

/// Simple Writer implementation that captures data to a Data buffer
private final class DataWriter: Writer, @unchecked Sendable {
    private(set) var data = Data()
    private let lock = NSLock()

    func write(_ buffer: Data) throws {
        lock.lock()
        defer { lock.unlock() }
        data.append(buffer)
    }

    func close() throws {
        // No-op: data is already captured
    }
}

/// Handlers for Docker Engine API container endpoints
/// Reference: Documentation/DOCKER_ENGINE_API_SPEC.md
public struct ContainerHandlers: Sendable {
    private let containerManager: ContainerBridge.ContainerManager
    private let imageManager: ImageManager
    private let execManager: ExecManager
    private let logger: Logger

    public init(containerManager: ContainerBridge.ContainerManager, imageManager: ImageManager, execManager: ExecManager, logger: Logger) {
        self.containerManager = containerManager
        self.imageManager = imageManager
        self.execManager = execManager
        self.logger = logger
    }

    /// Get error description from Swift errors
    private func errorDescription(_ error: Error) -> String {
        return error.localizedDescription
    }

    /// Check if a container is the control plane
    private func isControlPlane(id: String) async -> Bool {
        guard let container = try? await containerManager.getContainer(id: id) else {
            return false
        }
        return container.config.labels["com.arca.internal"] == "true" &&
               container.config.labels["com.arca.role"] == "control-plane"
    }

    /// Handle GET /containers/json
    /// Lists all containers
    ///
    /// Query parameters:
    /// - all: Show all containers (default shows just running)
    /// - limit: Limit the number of results
    /// - size: Return container size information
    /// - filters: JSON encoded filters
    public func handleListContainers(all: Bool = false, limit: Int? = nil, size: Bool = false, filters: [String: String] = [:]) async -> ContainerListResponse {
        logger.debug("Handling list containers request", metadata: [
            "all": "\(all)",
            "limit": "\(limit?.description ?? "none")",
            "size": "\(size)",
            "filters": "\(filters)"
        ])

        do {
            // Get containers from ContainerManager
            var containers = try await containerManager.listContainers(all: all, filters: filters)

            // Apply limit if specified
            if let limit = limit, limit > 0 {
                containers = Array(containers.prefix(limit))
            }

            // Convert to Docker API format
            let dockerContainers = containers.map { summary in
                ContainerListItem(
                    id: summary.id,
                    names: summary.names,
                    image: summary.image,
                    imageID: summary.imageID,
                    command: summary.command,
                    created: summary.created,
                    state: summary.state,
                    status: summary.status,
                    ports: summary.ports.map { port in
                        Port(
                            privatePort: port.privatePort,
                            publicPort: port.publicPort,
                            type: port.type,
                            ip: port.ip
                        )
                    },
                    labels: summary.labels,
                    sizeRw: size ? summary.sizeRw : nil,
                    sizeRootFs: size ? summary.sizeRootFs : nil
                )
            }

            logger.info("Listed containers", metadata: [
                "count": "\(dockerContainers.count)"
            ])

            return ContainerListResponse(containers: dockerContainers)
        } catch {
            logger.error("Failed to list containers", metadata: [
                "error": "\(error)"
            ])

            return ContainerListResponse(containers: [], error: error)
        }
    }

    /// Handle POST /containers/create
    /// Creates a new container
    public func handleCreateContainer(
        request: ContainerCreateRequest,
        name: String?
    ) async -> Result<ContainerCreateResponse, ContainerError> {
        logger.info("Handling create container request", metadata: [
            "image": "\(request.image)",
            "name": "\(name ?? "auto")"
        ])

        // Check if image exists locally - return error if not (let Docker CLI handle the pull)
        do {
            _ = try await imageManager.getImage(nameOrId: request.image)
        } catch {
            logger.warning("Image not found, returning error to trigger client-side pull", metadata: [
                "image": "\(request.image)"
            ])
            return .failure(.imageNotFound(request.image))
        }

        do {
            // Convert RestartPolicyCreate to RestartPolicy
            let restartPolicy: RestartPolicy? = request.hostConfig?.restartPolicy.map { policy in
                RestartPolicy(
                    name: policy.name,
                    maximumRetryCount: policy.maximumRetryCount ?? 0
                )
            }

            let containerID = try await containerManager.createContainer(
                image: request.image,
                name: name,
                entrypoint: request.entrypoint,
                command: request.cmd,
                env: request.env,
                workingDir: request.workingDir,
                labels: request.labels,
                attachStdin: request.attachStdin ?? false,
                attachStdout: request.attachStdout ?? false,
                attachStderr: request.attachStderr ?? false,
                tty: request.tty ?? false,
                openStdin: request.openStdin ?? false,
                networkMode: request.hostConfig?.networkMode,
                restartPolicy: restartPolicy,
                binds: request.hostConfig?.binds,
                volumes: request.volumes?.mapValues { $0.value }  // Convert AnyCodable to Any
            )

            logger.info("Container created", metadata: [
                "id": "\(containerID)"
            ])

            return .success(ContainerCreateResponse(id: containerID))
        } catch {
            logger.error("Failed to create container", metadata: [
                "error": "\(error)"
            ])

            return .failure(ContainerError.creationFailed(errorDescription(error)))
        }
    }

    /// Handle POST /containers/{id}/start
    /// Starts a container
    public func handleStartContainer(id: String) async -> Result<Void, ContainerError> {
        logger.info("Handling start container request", metadata: [
            "id": "\(id)"
        ])

        do {
            try await containerManager.startContainer(id: id)

            logger.info("Container started", metadata: [
                "id": "\(id)"
            ])

            return .success(())
        } catch {
            logger.error("Failed to start container", metadata: [
                "id": "\(id)",
                "error": "\(error)"
            ])

            return .failure(ContainerError.startFailed(errorDescription(error)))
        }
    }

    /// Handle POST /containers/{id}/stop
    /// Stops a container
    public func handleStopContainer(id: String, timeout: Int?) async -> Result<Void, ContainerError> {
        logger.info("Handling stop container request", metadata: [
            "id": "\(id)",
            "timeout": "\(timeout ?? 10)"
        ])

        // Protect control plane from being stopped by users
        if await isControlPlane(id: id) {
            logger.warning("Attempted to stop control plane container", metadata: ["id": "\(id)"])
            return .failure(ContainerError.operationNotPermitted(
                "Cannot stop the control plane container 'arca-control-plane'. " +
                "This container is managed by the Arca daemon and uses restart policy 'always'. " +
                "It will automatically restart if stopped."
            ))
        }

        do {
            try await containerManager.stopContainer(id: id, timeout: timeout)

            logger.info("Container stopped", metadata: [
                "id": "\(id)"
            ])

            return .success(())
        } catch let error as ContainerManagerError {
            logger.error("Failed to stop container", metadata: [
                "id": "\(id)",
                "error": "\(error)"
            ])

            // Map ContainerManagerError to appropriate ContainerError
            switch error {
            case .containerNotFound:
                return .failure(ContainerError.notFound(id))
            default:
                return .failure(ContainerError.stopFailed(error.description))
            }
        } catch {
            logger.error("Failed to stop container", metadata: [
                "id": "\(id)",
                "error": "\(error)"
            ])

            return .failure(ContainerError.stopFailed(errorDescription(error)))
        }
    }

    /// Handle POST /containers/{id}/restart
    /// Restarts a container
    public func handleRestartContainer(id: String, timeout: Int?) async -> Result<Void, ContainerError> {
        logger.info("Handling restart container request", metadata: [
            "id": "\(id)",
            "timeout": "\(timeout ?? 10)"
        ])

        // Protect control plane from being restarted by users
        if await isControlPlane(id: id) {
            logger.warning("Attempted to restart control plane container", metadata: ["id": "\(id)"])
            return .failure(ContainerError.operationNotPermitted(
                "Cannot restart the control plane container 'arca-control-plane'. " +
                "This container is managed by the Arca daemon and uses restart policy 'always'."
            ))
        }

        do {
            // Stop the container first (if running) - this is idempotent
            try await containerManager.stopContainer(id: id, timeout: timeout)

            logger.debug("Container stopped for restart", metadata: ["id": "\(id)"])

            // Start the container
            try await containerManager.startContainer(id: id)

            logger.info("Container restarted", metadata: ["id": "\(id)"])

            return .success(())
        } catch let error as ContainerManagerError {
            logger.error("Failed to restart container", metadata: [
                "id": "\(id)",
                "error": "\(error)"
            ])

            // Map ContainerManagerError to appropriate ContainerError
            switch error {
            case .containerNotFound:
                return .failure(ContainerError.notFound(id))
            default:
                return .failure(ContainerError.restartFailed(error.description))
            }
        } catch {
            logger.error("Failed to restart container", metadata: [
                "id": "\(id)",
                "error": "\(error)"
            ])

            return .failure(ContainerError.restartFailed(errorDescription(error)))
        }
    }

    /// Handle POST /containers/{id}/rename
    /// Renames a container
    public func handleRenameContainer(id: String, newName: String) async -> Result<Void, ContainerError> {
        logger.info("Handling rename container request", metadata: [
            "id": "\(id)",
            "newName": "\(newName)"
        ])

        // Protect control plane from being renamed
        if await isControlPlane(id: id) {
            logger.warning("Attempted to rename control plane container", metadata: ["id": "\(id)"])
            return .failure(ContainerError.operationNotPermitted(
                "Cannot rename the control plane container 'arca-control-plane'. " +
                "This container is managed by the Arca daemon."
            ))
        }

        do {
            try await containerManager.renameContainer(id: id, newName: newName)

            logger.info("Container renamed successfully", metadata: [
                "id": "\(id)",
                "newName": "\(newName)"
            ])

            return .success(())
        } catch let error as ContainerManagerError {
            logger.error("Failed to rename container", metadata: [
                "id": "\(id)",
                "error": "\(error)"
            ])

            // Map ContainerManagerError to appropriate ContainerError
            switch error {
            case .containerNotFound:
                return .failure(ContainerError.notFound(id))
            case .invalidConfiguration(let msg) where msg.contains("already in use"):
                return .failure(ContainerError.nameAlreadyInUse(newName))
            default:
                return .failure(ContainerError.renameFailed(error.description))
            }
        } catch {
            logger.error("Failed to rename container", metadata: [
                "id": "\(id)",
                "error": "\(error)"
            ])

            return .failure(ContainerError.renameFailed(errorDescription(error)))
        }
    }

    /// Handle POST /containers/{id}/pause
    /// Pauses a running container
    public func handlePauseContainer(id: String) async -> Result<Void, ContainerError> {
        logger.info("Handling pause container request", metadata: ["id": "\(id)"])

        do {
            try await containerManager.pauseContainer(id: id)

            logger.info("Container paused successfully", metadata: ["id": "\(id)"])

            return .success(())
        } catch let error as ContainerManagerError {
            logger.error("Failed to pause container", metadata: [
                "id": "\(id)",
                "error": "\(error)"
            ])

            // Map ContainerManagerError to appropriate ContainerError
            switch error {
            case .containerNotFound:
                return .failure(ContainerError.notFound(id))
            case .invalidConfiguration(let msg):
                return .failure(ContainerError.invalidRequest(msg))
            default:
                return .failure(ContainerError.pauseFailed(error.description))
            }
        } catch {
            logger.error("Failed to pause container", metadata: [
                "id": "\(id)",
                "error": "\(error)"
            ])

            return .failure(ContainerError.pauseFailed(errorDescription(error)))
        }
    }

    /// Handle POST /containers/{id}/unpause
    /// Unpauses a paused container
    public func handleUnpauseContainer(id: String) async -> Result<Void, ContainerError> {
        logger.info("Handling unpause container request", metadata: ["id": "\(id)"])

        do {
            try await containerManager.unpauseContainer(id: id)

            logger.info("Container unpaused successfully", metadata: ["id": "\(id)"])

            return .success(())
        } catch let error as ContainerManagerError {
            logger.error("Failed to unpause container", metadata: [
                "id": "\(id)",
                "error": "\(error)"
            ])

            // Map ContainerManagerError to appropriate ContainerError
            switch error {
            case .containerNotFound:
                return .failure(ContainerError.notFound(id))
            case .invalidConfiguration(let msg):
                return .failure(ContainerError.invalidRequest(msg))
            default:
                return .failure(ContainerError.unpauseFailed(error.description))
            }
        } catch {
            logger.error("Failed to unpause container", metadata: [
                "id": "\(id)",
                "error": "\(error)"
            ])

            return .failure(ContainerError.unpauseFailed(errorDescription(error)))
        }
    }

    /// Handle GET /containers/{id}/stats
    /// Gets container resource usage statistics
    public func handleGetContainerStats(id: String) async -> Result<ContainerStatsResponse, ContainerError> {
        logger.info("Handling get container stats request", metadata: ["id": "\(id)"])

        do {
            // Get container name for response
            guard let containerInfo = try await containerManager.getContainer(id: id) else {
                return .failure(ContainerError.notFound(id))
            }

            // Get statistics from container manager
            let stats = try await containerManager.getContainerStats(id: id)

            // Transform to Docker format
            let now = ISO8601DateFormatter().string(from: Date())
            let dockerStats = transformToDockerStats(
                stats: stats,
                containerID: containerInfo.id,
                containerName: containerInfo.name ?? "",
                timestamp: now
            )

            logger.info("Container stats retrieved successfully", metadata: ["id": "\(id)"])

            return .success(dockerStats)
        } catch let error as ContainerManagerError {
            logger.error("Failed to get container stats", metadata: [
                "id": "\(id)",
                "error": "\(error)"
            ])

            switch error {
            case .containerNotFound:
                return .failure(ContainerError.notFound(id))
            case .invalidConfiguration(let msg):
                return .failure(ContainerError.invalidRequest(msg))
            default:
                return .failure(ContainerError.statsFailed(error.description))
            }
        } catch {
            logger.error("Failed to get container stats", metadata: [
                "id": "\(id)",
                "error": "\(error)"
            ])

            return .failure(ContainerError.statsFailed(errorDescription(error)))
        }
    }

    /// Transform Apple ContainerStatistics to Docker stats format
    private func transformToDockerStats(
        stats: Containerization.ContainerStatistics,
        containerID: String,
        containerName: String,
        timestamp: String
    ) -> ContainerStatsResponse {
        // Convert microseconds to nanoseconds for Docker compatibility
        let cpuUsageNano = stats.cpu.usageUsec * 1000
        let userUsageNano = stats.cpu.userUsec * 1000
        let systemUsageNano = stats.cpu.systemUsec * 1000
        let throttledTimeNano = stats.cpu.throttledTimeUsec * 1000

        // Build CPU stats
        let cpuUsage = CPUUsage(
            totalUsage: cpuUsageNano,
            usageInKernelmode: systemUsageNano,
            usageInUsermode: userUsageNano
        )

        let throttlingData = ThrottlingData(
            periods: stats.cpu.throttlingPeriods,
            throttledPeriods: stats.cpu.throttledPeriods,
            throttledTime: throttledTimeNano
        )

        let cpuStats = CPUStats(
            cpuUsage: cpuUsage,
            systemCpuUsage: cpuUsageNano,  // Approximate
            onlineCpus: ProcessInfo.processInfo.processorCount,
            throttlingData: throttlingData
        )

        // Build memory stats
        let memoryStatsDetails = MemoryStatsDetails(
            cache: stats.memory.cacheBytes,
            pgfault: stats.memory.pageFaults,
            pgmajfault: stats.memory.majorPageFaults
        )

        let memoryStats = MemoryStats(
            usage: stats.memory.usageBytes,
            limit: stats.memory.limitBytes,
            stats: memoryStatsDetails
        )

        // Build PID stats
        let pidsStats = PidsStats(
            current: stats.process.current,
            limit: stats.process.limit
        )

        // Build block I/O stats
        var blkioEntries: [BlkioStatEntry] = []
        for device in stats.blockIO.devices {
            blkioEntries.append(BlkioStatEntry(
                major: device.major,
                minor: device.minor,
                op: "Read",
                value: device.readBytes
            ))
            blkioEntries.append(BlkioStatEntry(
                major: device.major,
                minor: device.minor,
                op: "Write",
                value: device.writeBytes
            ))
        }

        let blkioStats = BlkioStats(
            ioServiceBytesRecursive: blkioEntries.isEmpty ? nil : blkioEntries
        )

        // Build network stats
        var networks: [String: NetworkStats] = [:]
        for netStat in stats.networks {
            networks[netStat.interface] = NetworkStats(
                rxBytes: netStat.receivedBytes,
                rxPackets: netStat.receivedPackets,
                rxErrors: netStat.receivedErrors,
                rxDropped: 0,  // Not available in Apple's stats
                txBytes: netStat.transmittedBytes,
                txPackets: netStat.transmittedPackets,
                txErrors: netStat.transmittedErrors,
                txDropped: 0  // Not available in Apple's stats
            )
        }

        return ContainerStatsResponse(
            id: containerID,
            name: containerName,
            read: timestamp,
            preread: timestamp,  // Same as read for non-streaming
            pidsStats: pidsStats,
            cpuStats: cpuStats,
            precpuStats: cpuStats,  // Same as cpuStats for single-shot
            memoryStats: memoryStats,
            blkioStats: blkioStats,
            networks: networks.isEmpty ? nil : networks
        )
    }

    /// Handle GET /containers/{id}/stats with streaming support
    /// Streams container stats when stream=true (default), or returns single snapshot when stream=false
    public func handleGetContainerStatsStreaming(id: String, stream: Bool) async -> HTTPResponseType {
        logger.info("Handling container stats request (streaming)", metadata: [
            "id": "\(id)",
            "stream": "\(stream)"
        ])

        // Verify container exists and is running
        guard let containerInfo = try? await containerManager.getContainer(id: id) else {
            return .standard(HTTPResponse.notFound("container", id: id))
        }

        // Container must be running to get stats
        if !containerInfo.state.running {
            return .standard(HTTPResponse.error(
                "Container is not running",
                status: .internalServerError
            ))
        }

        // For non-streaming, get a single snapshot
        if !stream {
            let result = await handleGetContainerStats(id: id)
            switch result {
            case .success(let stats):
                return .standard(HTTPResponse.ok(stats))
            case .failure(let error):
                return .standard(HTTPResponse.error(
                    error.localizedDescription,
                    status: .internalServerError
                ))
            }
        }

        // Streaming response - poll stats every 1 second
        var headers = HTTPHeaders()
        headers.add(name: "Content-Type", value: "application/json")

        return .streaming(status: .ok, headers: headers) { writer in
            var previousStats: Containerization.ContainerStatistics?
            var previousTimestamp: String?

            do {
                // Poll stats until the stream is cancelled or container stops
                while true {
                    // Check if container is still running
                    guard let currentInfo = try? await self.containerManager.getContainer(id: id),
                          currentInfo.state.running else {
                        // Container stopped, finish the stream
                        try await writer.finish()
                        return
                    }

                    do {
                        // Get current stats
                        let currentStats = try await self.containerManager.getContainerStats(id: id)
                        let currentTimestamp = ISO8601DateFormatter().string(from: Date())

                        // Build stats response with previous values for deltas
                        var statsResponse = self.transformToDockerStats(
                            stats: currentStats,
                            containerID: containerInfo.id,
                            containerName: containerInfo.name ?? "",
                            timestamp: currentTimestamp
                        )

                        // Update preread and precpu stats if we have previous values
                        if let prevTimestamp = previousTimestamp {
                            statsResponse = ContainerStatsResponse(
                                id: statsResponse.id,
                                name: statsResponse.name,
                                read: statsResponse.read,
                                preread: prevTimestamp,
                                pidsStats: statsResponse.pidsStats,
                                cpuStats: statsResponse.cpuStats,
                                precpuStats: previousStats.map { prevStats in
                                    self.buildCPUStats(from: prevStats)
                                } ?? statsResponse.cpuStats,
                                memoryStats: statsResponse.memoryStats,
                                blkioStats: statsResponse.blkioStats,
                                networks: statsResponse.networks
                            )
                        }

                        // Encode and write JSON
                        let encoder = JSONEncoder()
                        encoder.outputFormatting = .withoutEscapingSlashes
                        encoder.dateEncodingStrategy = .iso8601
                        let jsonData = try encoder.encode(statsResponse)

                        // Docker stats format: newline-delimited JSON
                        var dataWithNewline = jsonData
                        dataWithNewline.append(contentsOf: "\n".utf8)

                        try await writer.write(dataWithNewline)

                        // Save for next iteration
                        previousStats = currentStats
                        previousTimestamp = currentTimestamp

                        // Wait 1 second before next poll (standard Docker stats interval)
                        try await Task.sleep(nanoseconds: 1_000_000_000)

                    } catch {
                        // Log error but continue trying
                        self.logger.error("Failed to get stats during streaming", metadata: [
                            "id": "\(id)",
                            "error": "\(error)"
                        ])

                        // If we get an error, wait a bit before retrying
                        try await Task.sleep(nanoseconds: 1_000_000_000)
                    }
                }
            } catch is CancellationError {
                // Stream was cancelled (client disconnected), this is normal
                self.logger.debug("Stats streaming cancelled", metadata: ["id": "\(id)"])
                try? await writer.finish()
            } catch {
                self.logger.error("Stats streaming error", metadata: [
                    "id": "\(id)",
                    "error": "\(error)"
                ])
                try? await writer.finish()
            }
        }
    }

    /// Helper to build CPUStats from ContainerStatistics (for precpu stats)
    private func buildCPUStats(from stats: Containerization.ContainerStatistics) -> CPUStats {
        let cpuUsageNano = stats.cpu.usageUsec * 1000
        let userUsageNano = stats.cpu.userUsec * 1000
        let systemUsageNano = stats.cpu.systemUsec * 1000
        let throttledTimeNano = stats.cpu.throttledTimeUsec * 1000

        let cpuUsage = CPUUsage(
            totalUsage: cpuUsageNano,
            usageInKernelmode: systemUsageNano,
            usageInUsermode: userUsageNano
        )

        let throttlingData = ThrottlingData(
            periods: stats.cpu.throttlingPeriods,
            throttledPeriods: stats.cpu.throttledPeriods,
            throttledTime: throttledTimeNano
        )

        return CPUStats(
            cpuUsage: cpuUsage,
            systemCpuUsage: cpuUsageNano,
            onlineCpus: ProcessInfo.processInfo.processorCount,
            throttlingData: throttlingData
        )
    }

    /// Handle DELETE /containers/{id}
    /// Removes a container
    public func handleRemoveContainer(id: String, force: Bool, removeVolumes: Bool) async -> Result<Void, ContainerError> {
        logger.info("Handling remove container request", metadata: [
            "id": "\(id)",
            "force": "\(force)",
            "volumes": "\(removeVolumes)"
        ])

        // Protect control plane from being removed by users
        if await isControlPlane(id: id) {
            logger.warning("Attempted to remove control plane container", metadata: ["id": "\(id)"])
            return .failure(ContainerError.operationNotPermitted(
                "Cannot remove the control plane container 'arca-control-plane'. " +
                "This container is managed by the Arca daemon and is required for networking. " +
                "Removing it would break all network functionality."
            ))
        }

        do {
            try await containerManager.removeContainer(id: id, force: force, removeVolumes: removeVolumes)

            logger.info("Container removed", metadata: [
                "id": "\(id)"
            ])

            return .success(())
        } catch {
            logger.error("Failed to remove container", metadata: [
                "id": "\(id)",
                "error": "\(error)"
            ])

            return .failure(ContainerError.removeFailed(errorDescription(error)))
        }
    }

    /// Handle GET /containers/{id}/json
    /// Inspects a container
    public func handleInspectContainer(id: String) async -> Result<ContainerInspect, ContainerError> {
        logger.info("Handling inspect container request", metadata: [
            "id": "\(id)"
        ])

        do {
            guard let container = try await containerManager.getContainer(id: id) else {
                logger.warning("Container not found", metadata: [
                    "id": "\(id)"
                ])
                return .failure(ContainerError.notFound(id))
            }

            // Convert internal Container type to Docker API ContainerInspect
            let inspect = ContainerInspect(
                id: container.id,
                created: ISO8601DateFormatter().string(from: container.created),
                path: container.path,
                args: container.args,
                state: ContainerStateInspect(
                    status: container.state.status,
                    running: container.state.running,
                    paused: container.state.paused,
                    restarting: container.state.restarting,
                    oomKilled: container.state.oomKilled,
                    dead: container.state.dead,
                    pid: container.state.pid,
                    exitCode: container.state.exitCode,
                    error: container.state.error,
                    startedAt: container.state.startedAt.map { ISO8601DateFormatter().string(from: $0) } ?? "0001-01-01T00:00:00Z",
                    finishedAt: container.state.finishedAt.map { ISO8601DateFormatter().string(from: $0) } ?? "0001-01-01T00:00:00Z"
                ),
                image: container.image,
                name: "/\(container.name)",
                hostConfig: HostConfigInspect(
                    binds: container.hostConfig.binds,
                    networkMode: container.hostConfig.networkMode,
                    portBindings: [:],  // TODO: Map port bindings
                    restartPolicy: RestartPolicyInspect(
                        name: container.hostConfig.restartPolicy.name,
                        maximumRetryCount: container.hostConfig.restartPolicy.maximumRetryCount
                    ),
                    autoRemove: container.hostConfig.autoRemove,
                    privileged: container.hostConfig.privileged
                ),
                config: ContainerConfigInspect(
                    hostname: container.config.hostname,
                    domainname: container.config.domainname,
                    user: container.config.user,
                    attachStdin: container.config.attachStdin,
                    attachStdout: container.config.attachStdout,
                    attachStderr: container.config.attachStderr,
                    tty: container.config.tty,
                    openStdin: container.config.openStdin,
                    stdinOnce: container.config.stdinOnce,
                    env: container.config.env,
                    cmd: container.config.cmd,
                    image: container.config.image,
                    volumes: nil,
                    workingDir: container.config.workingDir,
                    entrypoint: container.config.entrypoint,
                    labels: container.config.labels
                ),
                networkSettings: NetworkSettingsInspect(
                    ipAddress: container.networkSettings.ipAddress,
                    ipPrefixLen: container.networkSettings.ipPrefixLen,
                    gateway: container.networkSettings.gateway,
                    macAddress: container.networkSettings.macAddress,
                    networks: container.networkSettings.networks.mapValues { endpoint in
                        NetworkEndpointInspect(
                            networkID: endpoint.networkID,
                            endpointID: endpoint.endpointID,
                            gateway: endpoint.gateway,
                            ipAddress: endpoint.ipAddress,
                            ipPrefixLen: endpoint.ipPrefixLen,
                            macAddress: endpoint.macAddress
                        )
                    }
                )
            )

            logger.info("Container inspected", metadata: [
                "id": "\(id)"
            ])

            return .success(inspect)
        } catch {
            logger.error("Failed to inspect container", metadata: [
                "id": "\(id)",
                "error": "\(error)"
            ])

            return .failure(ContainerError.inspectFailed(errorDescription(error)))
        }
    }

    /// Handle GET /containers/{id}/logs
    /// Gets container logs
    ///
    /// Query parameters:
    /// - follow: Keep connection after returning logs (not yet supported)
    /// - stdout: Return logs from stdout
    /// - stderr: Return logs from stderr
    /// - since: Only return logs since this time (UNIX timestamp)
    /// - until: Only return logs before this time (UNIX timestamp)
    /// - timestamps: Add timestamps to every log line
    /// - tail: Only return this number of log lines from the end
    public func handleLogsContainer(idOrName: String, stdout: Bool, stderr: Bool, follow: Bool, since: Int?, until: Int?, timestamps: Bool, tail: String?) async -> Result<Data, ContainerError> {
        logger.info("Handling container logs request", metadata: [
            "id_or_name": "\(idOrName)",
            "stdout": "\(stdout)",
            "stderr": "\(stderr)",
            "follow": "\(follow)",
            "timestamps": "\(timestamps)",
            "tail": "\(tail ?? "all")"
        ])

        // Resolve container name or ID to Docker ID
        guard let dockerID = await containerManager.resolveContainer(idOrName: idOrName) else {
            logger.warning("Container not found", metadata: [
                "id_or_name": "\(idOrName)"
            ])
            return .failure(ContainerError.notFound(idOrName))
        }

        logger.debug("Resolved container", metadata: [
            "input": "\(idOrName)",
            "docker_id": "\(dockerID)"
        ])

        // Get log file paths
        guard let logPaths = containerManager.getLogPaths(dockerID: dockerID) else {
            logger.warning("No logs found for container", metadata: ["docker_id": "\(dockerID)"])
            return .failure(ContainerError.notFound("logs for \(idOrName)"))
        }

        do {
            // Retrieve and filter logs
            let logs = try retrieveLogs(
                logPaths: logPaths,
                stdout: stdout,
                stderr: stderr,
                since: since,
                until: until,
                timestamps: timestamps,
                tail: tail
            )

            logger.info("Container logs retrieved", metadata: [
                "id": "\(dockerID)",
                "entries": "\(logs.count)"
            ])

            // Convert to Docker multiplexed stream format
            let multiplexedData = formatMultiplexedStream(logs: logs)
            return .success(multiplexedData)
        } catch {
            logger.error("Failed to retrieve logs", metadata: [
                "docker_id": "\(dockerID)",
                "error": "\(error)"
            ])
            return .failure(ContainerError.inspectFailed("Failed to retrieve logs: \(error)"))
        }
    }

    /// Handle GET /containers/{id}/logs with streaming support
    /// Streams container logs when follow=true
    public func handleLogsContainerStreaming(
        idOrName: String,
        stdout: Bool,
        stderr: Bool,
        follow: Bool,
        since: Int?,
        until: Int?,
        timestamps: Bool,
        tail: String?
    ) async -> HTTPResponseType {
        logger.info("Handling container logs request (streaming)", metadata: [
            "id_or_name": "\(idOrName)",
            "follow": "\(follow)"
        ])

        // Resolve container
        guard let dockerID = await containerManager.resolveContainer(idOrName: idOrName) else {
            return .standard(HTTPResponse.error("No such container: \(idOrName)", status: .notFound))
        }

        // Get log file paths
        guard let logPaths = containerManager.getLogPaths(dockerID: dockerID) else {
            return .standard(HTTPResponse.error("No logs found for container", status: .notFound))
        }

        // If not following, use standard response
        if !follow {
            do {
                let logs = try retrieveLogs(
                    logPaths: logPaths,
                    stdout: stdout,
                    stderr: stderr,
                    since: since,
                    until: until,
                    timestamps: timestamps,
                    tail: tail
                )
                let multiplexedData = formatMultiplexedStream(logs: logs)
                return .standard(HTTPResponse(
                    status: .ok,
                    headers: HTTPHeaders([("Content-Type", "application/vnd.docker.raw-stream")]),
                    body: multiplexedData
                ))
            } catch {
                return .standard(HTTPResponse.error("Failed to retrieve logs: \(error)", status: .internalServerError))
            }
        }

        // Streaming response
        var headers = HTTPHeaders()
        headers.add(name: "Content-Type", value: "application/vnd.docker.raw-stream")

        return .streaming(status: .ok, headers: headers) { writer in
            do {
                // Stream existing logs first
                let existingLogs = try self.retrieveLogs(
                    logPaths: logPaths,
                    stdout: stdout,
                    stderr: stderr,
                    since: since,
                    until: until,
                    timestamps: timestamps,
                    tail: tail
                )

                let existingData = self.formatMultiplexedStream(logs: existingLogs)
                if !existingData.isEmpty {
                    try await writer.write(existingData)
                }

                // If following, watch for new log entries
                if follow {
                    try await self.streamNewLogs(
                        dockerID: dockerID,
                        logPaths: logPaths,
                        stdout: stdout,
                        stderr: stderr,
                        timestamps: timestamps,
                        writer: writer
                    )
                }

                try await writer.finish()
            } catch {
                self.logger.error("Log streaming error", metadata: ["error": "\(error)"])
                try? await writer.finish()
            }
        }
    }

    /// Stream new log entries as they appear
    private func streamNewLogs(
        dockerID: String,
        logPaths: ContainerBridge.ContainerLogManager.LogPaths,
        stdout: Bool,
        stderr: Bool,
        timestamps: Bool,
        writer: HTTPStreamWriter
    ) async throws {
        // Track last read positions
        var stdoutPosition = try? getFileSize(logPaths.stdoutPath)
        var stderrPosition = try? getFileSize(logPaths.stderrPath)

        // Poll for new log data every 100ms until container exits
        while await containerManager.isContainerRunning(dockerID: dockerID) {
            try await Task.sleep(nanoseconds: 100_000_000) // 100ms

            // Check stdout for new data
            if stdout, let currentSize = try? getFileSize(logPaths.stdoutPath),
               currentSize > (stdoutPosition ?? 0) {
                if let newData = try? readNewLogData(
                    path: logPaths.stdoutPath,
                    from: stdoutPosition ?? 0,
                    streamType: "stdout",
                    timestamps: timestamps
                ) {
                    try await writer.write(newData)
                    stdoutPosition = currentSize
                }
            }

            // Check stderr for new data
            if stderr, let currentSize = try? getFileSize(logPaths.stderrPath),
               currentSize > (stderrPosition ?? 0) {
                if let newData = try? readNewLogData(
                    path: logPaths.stderrPath,
                    from: stderrPosition ?? 0,
                    streamType: "stderr",
                    timestamps: timestamps
                ) {
                    try await writer.write(newData)
                    stderrPosition = currentSize
                }
            }
        }
    }

    /// Get file size in bytes
    private func getFileSize(_ path: URL) throws -> UInt64 {
        let attributes = try FileManager.default.attributesOfItem(atPath: path.path)
        return attributes[.size] as? UInt64 ?? 0
    }

    /// Read new log data from position to end of file
    private func readNewLogData(path: URL, from position: UInt64, streamType: String, timestamps: Bool) throws -> Data {
        let fileHandle = try FileHandle(forReadingFrom: path)
        defer { try? fileHandle.close() }

        try fileHandle.seek(toOffset: position)
        let data = fileHandle.readDataToEndOfFile()

        guard let content = String(data: data, encoding: .utf8) else {
            return Data()
        }

        let lines = content.components(separatedBy: .newlines)
        var logEntries: [LogEntry] = []

        for line in lines {
            guard !line.isEmpty else { continue }

            guard let lineData = line.data(using: .utf8),
                  let json = try? JSONSerialization.jsonObject(with: lineData) as? [String: Any],
                  let logStream = json["stream"] as? String,
                  let logMessage = json["log"] as? String,
                  let timeString = json["time"] as? String else {
                continue
            }

            let formatter = ISO8601DateFormatter()
            guard let timestamp = formatter.date(from: timeString) else {
                continue
            }

            if logStream == streamType {
                logEntries.append(LogEntry(
                    stream: logStream,
                    message: logMessage,
                    timestamp: timestamp,
                    includeTimestamp: timestamps
                ))
            }
        }

        return formatMultiplexedStream(logs: logEntries)
    }

    /// Retrieve and filter container logs from JSON log files
    /// Returns array of log entries with stream type, message, and timestamp
    private func retrieveLogs(
        logPaths: ContainerBridge.ContainerLogManager.LogPaths,
        stdout: Bool,
        stderr: Bool,
        since: Int?,
        until: Int?,
        timestamps: Bool,
        tail: String?
    ) throws -> [LogEntry] {
        var allLogs: [LogEntry] = []

        // Helper to parse log files
        func parseLogs(from path: URL, forStream stream: String) throws {
            guard FileManager.default.fileExists(atPath: path.path) else {
                return
            }

            let content = try String(contentsOf: path, encoding: .utf8)
            let lines = content.components(separatedBy: .newlines)

            for line in lines {
                guard !line.isEmpty else { continue }

                // Parse JSON log entry
                guard let data = line.data(using: .utf8),
                      let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
                      let logStream = json["stream"] as? String,
                      let logMessage = json["log"] as? String,
                      let timeString = json["time"] as? String else {
                    continue
                }

                // Parse timestamp
                let formatter = ISO8601DateFormatter()
                guard let timestamp = formatter.date(from: timeString) else {
                    continue
                }

                allLogs.append(LogEntry(
                    stream: logStream,
                    message: logMessage,
                    timestamp: timestamp,
                    includeTimestamp: timestamps
                ))
            }
        }

        // Read from stdout log file if requested
        if stdout {
            try parseLogs(from: logPaths.stdoutPath, forStream: "stdout")
        }

        // Read from stderr log file if requested
        if stderr {
            try parseLogs(from: logPaths.stderrPath, forStream: "stderr")
        }

        // Sort by timestamp (logs from different streams need to be interleaved chronologically)
        allLogs.sort { $0.timestamp < $1.timestamp }

        // Filter by time range
        if let since = since {
            let sinceDate = Date(timeIntervalSince1970: TimeInterval(since))
            allLogs = allLogs.filter { $0.timestamp >= sinceDate }
        }

        if let until = until {
            let untilDate = Date(timeIntervalSince1970: TimeInterval(until))
            allLogs = allLogs.filter { $0.timestamp <= untilDate }
        }

        // Apply tail limit
        if let tailStr = tail, let tailCount = Int(tailStr) {
            allLogs = Array(allLogs.suffix(tailCount))
        }

        return allLogs
    }

    /// Format log entries as Docker multiplexed stream
    /// Docker format: [stream_type (1 byte)][padding (3 bytes)][size (4 bytes big-endian)][payload]
    /// Stream types: 0=stdin, 1=stdout, 2=stderr
    private func formatMultiplexedStream(logs: [LogEntry]) -> Data {
        var result = Data()
        let formatter = ISO8601DateFormatter()

        for entry in logs {
            // Determine stream type
            let streamType: UInt8 = entry.stream == "stdout" ? 1 : 2

            // Format message (with timestamp if requested)
            var message = entry.message
            if entry.includeTimestamp {
                let timestampStr = formatter.string(from: entry.timestamp)
                message = "\(timestampStr) \(message)"
            }

            // Convert message to data
            guard let messageData = message.data(using: .utf8) else {
                continue
            }

            // Build frame header: [stream_type][padding][size]
            var header = Data()
            header.append(streamType)                    // 1 byte: stream type
            header.append(contentsOf: [0, 0, 0])        // 3 bytes: padding

            // 4 bytes: size (big-endian UInt32)
            let size = UInt32(messageData.count)
            header.append(UInt8((size >> 24) & 0xFF))
            header.append(UInt8((size >> 16) & 0xFF))
            header.append(UInt8((size >> 8) & 0xFF))
            header.append(UInt8(size & 0xFF))

            // Append header + payload
            result.append(header)
            result.append(messageData)
        }

        return result
    }

    /// Internal structure for log entry parsing
    private struct LogEntry {
        let stream: String
        let message: String
        let timestamp: Date
        let includeTimestamp: Bool
    }

    /// Handle POST /containers/{id}/wait
    /// Wait for a container to stop
    public func handleWaitContainer(idOrName: String) async -> Result<Int, ContainerError> {
        logger.info("Handling container wait request", metadata: [
            "id_or_name": "\(idOrName)"
        ])

        // Resolve container name or ID to Docker ID
        guard let dockerID = await containerManager.resolveContainer(idOrName: idOrName) else {
            logger.warning("Container not found", metadata: [
                "id_or_name": "\(idOrName)"
            ])
            return .failure(ContainerError.notFound(idOrName))
        }

        do {
            // Wait for container to finish
            let exitCode = try await containerManager.waitContainer(id: dockerID)

            logger.info("Container wait completed", metadata: [
                "id": "\(dockerID)",
                "exit_code": "\(exitCode)"
            ])

            return .success(exitCode)
        } catch {
            logger.error("Failed to wait for container", metadata: [
                "id": "\(dockerID)",
                "error": "\(error)"
            ])
            return .failure(ContainerError.inspectFailed(errorDescription(error)))
        }
    }

    /// Handle GET /containers/{id}/top
    /// List processes running inside a container
    public func handleTopContainer(id: String, psArgs: String?) async -> Result<ContainerTopResponse, ContainerError> {
        logger.info("Handling container top request", metadata: [
            "id": "\(id)",
            "ps_args": "\(psArgs ?? "-ef")"
        ])

        // Verify container exists and is running
        guard let containerInfo = try? await containerManager.getContainer(id: id) else {
            return .failure(ContainerError.notFound(id))
        }

        // Container must be running to list processes
        if !containerInfo.state.running {
            return .failure(ContainerError.invalidRequest("Container is not running"))
        }

        // Use exec to run ps inside the container
        let args = psArgs ?? "-ef"
        let command = ["/bin/ps", args]

        do {
            // Create exec instance
            let execID = try await execManager.createExec(
                containerID: id,
                cmd: command,
                env: nil,
                workingDir: nil,
                user: "root",
                tty: false,
                attachStdin: false,
                attachStdout: true,
                attachStderr: true
            )

            // Create writer to capture stdout
            let writer = DataWriter()

            // Start exec and capture output
            try await execManager.startExec(
                execID: execID,
                detach: false,
                tty: false,
                stdout: writer
            )

            // Get exec info to check exit code
            guard let execInfo = await execManager.getExecInfo(execID: execID),
                  let exitCode = execInfo.exitCode else {
                logger.error("Failed to get exec result", metadata: ["id": "\(id)"])
                return .failure(ContainerError.topFailed("Failed to get exec result"))
            }

            // Check if exec succeeded
            guard exitCode == 0, let output = String(data: writer.data, encoding: .utf8) else {
                logger.error("ps command failed", metadata: [
                    "id": "\(id)",
                    "exit_code": "\(exitCode)"
                ])
                return .failure(ContainerError.topFailed("Failed to execute ps command"))
            }

            // Parse ps output
            let response = parsePsOutput(output)

            logger.info("Container top completed", metadata: [
                "id": "\(id)",
                "process_count": "\(response.Processes.count)"
            ])

            return .success(response)
        } catch {
            logger.error("Failed to get container top", metadata: [
                "id": "\(id)",
                "error": "\(error)"
            ])
            return .failure(ContainerError.topFailed(errorDescription(error)))
        }
    }

    /// Parse ps command output into ContainerTopResponse
    private func parsePsOutput(_ output: String) -> ContainerTopResponse {
        let lines = output.components(separatedBy: .newlines)
            .map { $0.trimmingCharacters(in: .whitespaces) }
            .filter { !$0.isEmpty }

        guard !lines.isEmpty else {
            return ContainerTopResponse(Titles: [], Processes: [])
        }

        // First line is the header with column titles
        let headerLine = lines[0]
        let titles = headerLine.components(separatedBy: .whitespaces)
            .filter { !$0.isEmpty }

        // Remaining lines are processes
        var processes: [[String]] = []
        for line in lines.dropFirst() {
            // Split by whitespace, but handle command column which may contain spaces
            let parts = parseProcessLine(line, columnCount: titles.count)
            if !parts.isEmpty {
                processes.append(parts)
            }
        }

        return ContainerTopResponse(Titles: titles, Processes: processes)
    }

    /// Parse a single process line from ps output
    /// Handles the case where the last column (CMD) may contain spaces
    private func parseProcessLine(_ line: String, columnCount: Int) -> [String] {
        var parts: [String] = []
        var remaining = line

        // Parse first n-1 columns (before CMD)
        for _ in 0..<(columnCount - 1) {
            remaining = remaining.trimmingCharacters(in: .whitespaces)
            if remaining.isEmpty { break }

            // Find next whitespace
            if let spaceRange = remaining.rangeOfCharacter(from: .whitespaces) {
                let part = String(remaining[..<spaceRange.lowerBound])
                parts.append(part)
                remaining = String(remaining[spaceRange.upperBound...])
            } else {
                // No more whitespace, this is the last column
                parts.append(remaining)
                remaining = ""
                break
            }
        }

        // Remaining text is the CMD column (may contain spaces)
        if !remaining.isEmpty {
            parts.append(remaining.trimmingCharacters(in: .whitespaces))
        }

        return parts
    }

    /// Handle POST /containers/{id}/resize
    /// Resize the TTY for a container
    public func handleResizeContainer(id: String, height: Int?, width: Int?) async -> Result<Void, ContainerError> {
        logger.info("Handling container resize request", metadata: [
            "id": "\(id)",
            "height": "\(height ?? 0)",
            "width": "\(width ?? 0)"
        ])

        // TODO: Implement container TTY resizing via Containerization API
        // For now, just return success to prevent 404 errors
        // The container will use default terminal size
        logger.debug("Container resize not yet implemented, ignoring", metadata: ["id": "\(id)"])
        return .success(())
    }

    /// Handle POST /containers/prune
    /// Remove all stopped containers
    public func handlePruneContainers(filters: [String: [String]]? = nil) async -> Result<ContainerPruneResponse, ContainerError> {
        logger.info("Handling prune containers request", metadata: [
            "filters": "\(filters?.description ?? "none")"
        ])

        var deletedContainers: [String] = []
        var spaceReclaimed: Int64 = 0

        // Get all containers (including stopped ones)
        do {
            let containers = try await containerManager.listContainers(all: true)

            // Filter for stopped containers (not running)
            for container in containers {
                // Skip running containers
                guard container.state != "running" else {
                    continue
                }

                // Skip control plane
                if await isControlPlane(id: container.id) {
                    continue
                }

                // Calculate container size before removal
                let containerSize = container.sizeRootFs ?? container.sizeRw ?? 0

                // Attempt to remove the container
                do {
                    try await containerManager.removeContainer(id: container.id)
                    deletedContainers.append(container.id)
                    spaceReclaimed += containerSize

                    logger.debug("Pruned stopped container", metadata: [
                        "id": "\(container.id)",
                        "name": "\(container.names.first ?? container.id)",
                        "size": "\(containerSize)"
                    ])
                } catch {
                    logger.warning("Failed to prune container", metadata: [
                        "id": "\(container.id)",
                        "error": "\(error)"
                    ])
                    // Continue with other containers
                }
            }

            logger.info("Container prune complete", metadata: [
                "deleted": "\(deletedContainers.count)",
                "space": "\(spaceReclaimed)"
            ])

            return .success(ContainerPruneResponse(
                containersDeleted: deletedContainers,
                spaceReclaimed: spaceReclaimed
            ))
        } catch {
            logger.error("Failed to list containers for prune", metadata: ["error": "\(error)"])
            return .failure(ContainerError.invalidRequest("Failed to list containers: \(error)"))
        }
    }

    // MARK: - Archive Operations

    /// Get an archive of a filesystem resource in a container (GET /containers/{id}/archive)
    /// TODO: Implement file extraction from container VM filesystem
    public func handleGetArchive(id: String, path: String) async -> Result<Data, ContainerError> {
        logger.info("Getting archive from container", metadata: [
            "container_id": "\(id)",
            "path": "\(path)"
        ])

        // Resolve container ID
        guard let _ = await containerManager.resolveContainer(idOrName: id) else {
            return .failure(.notFound(id))
        }

        // TODO: Implement file extraction
        // Options:
        // 1. Extend vminitd tap-forwarder with ReadFile RPC
        // 2. Use temporary VirtioFS share
        // 3. Use vsock file transfer protocol
        return .failure(.invalidRequest("Archive extraction not yet implemented"))
    }

    /// Extract an archive to a directory in a container (PUT /containers/{id}/archive)
    ///
    /// Implementation notes:
    /// - Uses exec + tar for extraction (requires tar in container)
    /// - Temporarily starts containers in "created" state for injection
    /// - Returns container to original state after injection
    ///
    /// TODO: Implement generic file transfer via vminitd RPCs for containers without tar
    public func handlePutArchive(id: String, path: String, tarData: Data) async -> Result<Void, ContainerError> {
        logger.info("Putting archive to container", metadata: [
            "container_id": "\(id)",
            "path": "\(path)",
            "size": "\(tarData.count)"
        ])

        // Resolve container
        guard let containerID = await containerManager.resolveContainer(idOrName: id) else {
            return .failure(.notFound(id))
        }

        // Get container state to check if we need to start it
        guard let containerState = try? await containerManager.getContainer(id: containerID) else {
            return .failure(.notFound(id))
        }

        // Check container state - start if not running
        let wasCreated = containerState.state.status == "created" && !containerState.state.running
        if wasCreated {
            logger.info("Container in created state, temporarily starting for archive injection", metadata: [
                "container_id": "\(id)"
            ])

            do {
                try await containerManager.startContainer(id: containerID)
            } catch {
                return .failure(.startFailed("Failed to start container for archive injection: \(error.localizedDescription)"))
            }

            // Wait a moment for container to fully start
            try? await Task.sleep(for: .seconds(1))
        }

        // Create exec instance for tar extraction
        let execId: String
        do {
            execId = try await execManager.createExec(
                containerID: containerID,
                cmd: ["tar", "-xf", "-", "-C", path],
                env: nil,
                workingDir: nil,
                user: nil,
                tty: false,
                attachStdin: true,
                attachStdout: true,
                attachStderr: true
            )
        } catch {
            // If we started the container, stop it before returning error
            if wasCreated {
                try? await containerManager.stopContainer(id: containerID, timeout: 5)
            }
            return .failure(.invalidRequest("Failed to create exec for tar extraction: \(error.localizedDescription)"))
        }

        logger.debug("Created exec instance for tar extraction", metadata: [
            "exec_id": "\(execId)",
            "container_id": "\(id)"
        ])

        // Create a ReaderStream from the tar data
        let stdinReader = DataReaderStream(data: tarData)
        let stdoutWriter = DataWriter()
        let stderrWriter = DataWriter()

        // Start exec and stream tar data to stdin
        do {
            try await execManager.startExec(
                execID: execId,
                detach: false,
                tty: false,
                stdin: stdinReader,
                stdout: stdoutWriter,
                stderr: stderrWriter
            )
        } catch {
            // If we started the container, stop it before returning error
            if wasCreated {
                try? await containerManager.stopContainer(id: containerID, timeout: 5)
            }

            // Log stderr if tar command failed
            if !stderrWriter.data.isEmpty {
                logger.error("Tar extraction failed", metadata: [
                    "stderr": "\(String(data: stderrWriter.data, encoding: .utf8) ?? "<binary>")"
                ])
            }

            return .failure(.invalidRequest("Failed to extract tar archive: \(error.localizedDescription)"))
        }

        logger.info("Archive extracted successfully", metadata: [
            "container_id": "\(id)",
            "path": "\(path)"
        ])

        // If we started the container, stop it to return to created state
        if wasCreated {
            logger.info("Stopping container to return to created state", metadata: [
                "container_id": "\(id)"
            ])

            do {
                try await containerManager.stopContainer(id: containerID, timeout: 5)
            } catch {
                logger.warning("Failed to stop container after archive injection", metadata: [
                    "container_id": "\(id)",
                    "error": "\(error.localizedDescription)"
                ])
                // Don't fail the whole operation - archive was successfully injected
            }
        }

        return .success(())
    }
}

// MARK: - Response Types

/// Response wrapper for list containers
public struct ContainerListResponse {
    public let containers: [ContainerListItem]
    public let error: Error?

    public init(containers: [ContainerListItem], error: Error? = nil) {
        self.containers = containers
        self.error = error
    }
}

/// Response for POST /containers/prune
public struct ContainerPruneResponse: Codable {
    public let containersDeleted: [String]?
    public let spaceReclaimed: Int64

    enum CodingKeys: String, CodingKey {
        case containersDeleted = "ContainersDeleted"
        case spaceReclaimed = "SpaceReclaimed"
    }

    public init(containersDeleted: [String], spaceReclaimed: Int64) {
        self.containersDeleted = containersDeleted
        self.spaceReclaimed = spaceReclaimed
    }
}

// MARK: - Error Types

public enum ContainerError: Error, CustomStringConvertible {
    case creationFailed(String)
    case startFailed(String)
    case stopFailed(String)
    case restartFailed(String)
    case renameFailed(String)
    case pauseFailed(String)
    case unpauseFailed(String)
    case statsFailed(String)
    case topFailed(String)
    case removeFailed(String)
    case inspectFailed(String)
    case notFound(String)
    case invalidRequest(String)
    case imageNotFound(String)
    case nameAlreadyInUse(String)
    case operationNotPermitted(String)

    public var description: String {
        switch self {
        case .creationFailed(let msg):
            return "Failed to create container: \(msg)"
        case .startFailed(let msg):
            return "Failed to start container: \(msg)"
        case .stopFailed(let msg):
            return "Failed to stop container: \(msg)"
        case .restartFailed(let msg):
            return "Failed to restart container: \(msg)"
        case .renameFailed(let msg):
            return "Failed to rename container: \(msg)"
        case .pauseFailed(let msg):
            return "Failed to pause container: \(msg)"
        case .unpauseFailed(let msg):
            return "Failed to unpause container: \(msg)"
        case .statsFailed(let msg):
            return "Failed to get container stats: \(msg)"
        case .topFailed(let msg):
            return "Failed to list container processes: \(msg)"
        case .removeFailed(let msg):
            return "Failed to remove container: \(msg)"
        case .inspectFailed(let msg):
            return "Failed to inspect container: \(msg)"
        case .imageNotFound(let image):
            return "No such image: \(image)"
        case .notFound(let id):
            return "No such container: \(id)"
        case .invalidRequest(let msg):
            return "Invalid request: \(msg)"
        case .nameAlreadyInUse(let name):
            return "Conflict. The container name '\(name)' is already in use."
        case .operationNotPermitted(let msg):
            return "\(msg)"
        }
    }
}
